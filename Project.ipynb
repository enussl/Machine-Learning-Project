{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.imputation.mice import MICE, MICEData\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import itertools\n",
    "#import all the functions we wrote ourselves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_col=0 to make the companies/ the dates the indizes\n",
    "sp=pd.read_csv(\"Data/SP500.csv\",sep=\",\",index_col=0)\n",
    "gdp = pd.read_csv(\"Data/GDP USA.csv\", sep=\",\", index_col=0)\n",
    "infl = pd.read_csv(\"Data/INFL.csv\",sep=\",\", index_col=0)\n",
    "df14=pd.read_csv(\"Data/2014_Financial_Data.csv\",sep=\",\",index_col=0)\n",
    "df15=pd.read_csv(\"Data/2015_Financial_Data.csv\",sep=\",\",index_col=0)\n",
    "df16=pd.read_csv(\"Data/2016_Financial_Data.csv\",sep=\",\",index_col=0)\n",
    "df17=pd.read_csv(\"Data/2017_Financial_Data.csv\",sep=\",\",index_col=0)\n",
    "df18=pd.read_csv(\"Data/2018_Financial_Data.csv\",sep=\",\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for gdp and inflation per year\n",
    "gdp14 = gdp.iloc[1][0] * 1000000000\n",
    "gdp15 = gdp.iloc[2][0] * 1000000000\n",
    "gdp16 = gdp.iloc[3][0] * 1000000000\n",
    "gdp17 = gdp.iloc[4][0] * 1000000000\n",
    "gdp18 = gdp.iloc[5][0] * 1000000000\n",
    "\n",
    "infl14 = infl.iloc[0][0]\n",
    "infl15 = infl.iloc[1][0]\n",
    "infl16 = infl.iloc[2][0]\n",
    "infl17 = infl.iloc[3][0]\n",
    "infl18 = infl.iloc[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making one column with price var (neater if done here)\n",
    "#no need for pipeline\n",
    "\n",
    "df14.rename(columns={\"2015 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df15.rename(columns={\"2016 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df16.rename(columns={\"2017 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df17.rename(columns={\"2018 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df18.rename(columns={\"2019 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating year variable\n",
    "\n",
    "def year(data):\n",
    "    all_data=[df14,df15,df16,df17,df18]\n",
    "    count=0\n",
    "    for data in all_data:\n",
    "        data[\"year\"]=2014+count\n",
    "        count+=1\n",
    "    \n",
    "    #converting to cat. variable\n",
    "\n",
    "    all_data=[df14,df15,df16,df17,df18]\n",
    "\n",
    "    for data in all_data:\n",
    "        data[\"year\"]=data.year.astype(\"category\")\n",
    "\n",
    "#making a pipeline\n",
    "add_year=Pipeline(steps=[(\"add_year\",year(all_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the values with the perf. of the s&p to compare the companies to\n",
    "sp14_performance=sp.loc[\"2014-12-31\"].item()\n",
    "sp15_performance=sp.loc[\"2015-12-31\"].item()\n",
    "sp16_performance=sp.loc[\"2016-12-30\"].item()\n",
    "sp17_performance=sp.loc[\"2017-12-29\"].item()\n",
    "sp18_performance=sp.loc[\"2018-12-31\"].item()\n",
    "#list with the performances\n",
    "sp_performances=[sp14_performance,sp15_performance,sp16_performance,sp17_performance,sp18_performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using encoder to make the categorical vars as that will still work when using the pipeline\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "all_data=[df14,df15,df16,df17,df18]\n",
    "\n",
    "def categorize(data):\n",
    "\n",
    "    le=pp.LabelEncoder()\n",
    "\n",
    "    for data in all_data:\n",
    "        data[\"Sector\"]=le.fit_transform(data[\"Sector\"])\n",
    "        \n",
    "#making a pipeline fot that stuff\n",
    "sector_categorical=Pipeline(steps=[(\"sector_categorical\",categorize(all_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Revenue Growth</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>R&amp;D Expenses</th>\n",
       "      <th>SG&amp;A Expense</th>\n",
       "      <th>Operating Expenses</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>Interest Expense</th>\n",
       "      <th>Earnings before Tax</th>\n",
       "      <th>...</th>\n",
       "      <th>Inventory Growth</th>\n",
       "      <th>Asset Growth</th>\n",
       "      <th>Book Value per Share Growth</th>\n",
       "      <th>Debt Growth</th>\n",
       "      <th>R&amp;D Expense Growth</th>\n",
       "      <th>SG&amp;A Expenses Growth</th>\n",
       "      <th>Sector</th>\n",
       "      <th>PRICE_VAR</th>\n",
       "      <th>Class</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>7.440100e+10</td>\n",
       "      <td>-0.0713</td>\n",
       "      <td>3.903000e+10</td>\n",
       "      <td>3.537100e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.146100e+10</td>\n",
       "      <td>2.146100e+10</td>\n",
       "      <td>1.391000e+10</td>\n",
       "      <td>7.090000e+08</td>\n",
       "      <td>1.449400e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0217</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.1746</td>\n",
       "      <td>3</td>\n",
       "      <td>-9.323276</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIPS</th>\n",
       "      <td>3.734148e+09</td>\n",
       "      <td>1.1737</td>\n",
       "      <td>2.805625e+09</td>\n",
       "      <td>9.285226e+08</td>\n",
       "      <td>1.083303e+08</td>\n",
       "      <td>3.441414e+08</td>\n",
       "      <td>7.939267e+08</td>\n",
       "      <td>1.345959e+08</td>\n",
       "      <td>1.214869e+07</td>\n",
       "      <td>1.753823e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6484</td>\n",
       "      <td>1.7313</td>\n",
       "      <td>3</td>\n",
       "      <td>-25.512193</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KR</th>\n",
       "      <td>9.837500e+10</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>7.813800e+10</td>\n",
       "      <td>2.023700e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.519600e+10</td>\n",
       "      <td>1.751200e+10</td>\n",
       "      <td>2.725000e+09</td>\n",
       "      <td>4.430000e+08</td>\n",
       "      <td>2.270000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>3</td>\n",
       "      <td>33.118297</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>2.552641e+10</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>1.820268e+10</td>\n",
       "      <td>7.323734e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.561162e+09</td>\n",
       "      <td>6.586482e+09</td>\n",
       "      <td>7.372520e+08</td>\n",
       "      <td>4.245910e+08</td>\n",
       "      <td>2.502180e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0510</td>\n",
       "      <td>-0.0189</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>-0.0458</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>3</td>\n",
       "      <td>2.752291</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIS</th>\n",
       "      <td>1.790960e+10</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>1.153980e+10</td>\n",
       "      <td>6.369800e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.474300e+09</td>\n",
       "      <td>3.412400e+09</td>\n",
       "      <td>2.957400e+09</td>\n",
       "      <td>3.024000e+08</td>\n",
       "      <td>2.707700e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0220</td>\n",
       "      <td>3</td>\n",
       "      <td>12.897715</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRIV</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.755251e+06</td>\n",
       "      <td>3.755251e+06</td>\n",
       "      <td>-3.755251e+06</td>\n",
       "      <td>1.105849e+07</td>\n",
       "      <td>-1.482451e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0508</td>\n",
       "      <td>-0.1409</td>\n",
       "      <td>-0.0152</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2602</td>\n",
       "      <td>8</td>\n",
       "      <td>-90.962099</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YTEN</th>\n",
       "      <td>5.560000e+05</td>\n",
       "      <td>-0.4110</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.560000e+05</td>\n",
       "      <td>4.759000e+06</td>\n",
       "      <td>5.071000e+06</td>\n",
       "      <td>9.830000e+06</td>\n",
       "      <td>-9.274000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.170000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2323</td>\n",
       "      <td>-0.8602</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>-0.0993</td>\n",
       "      <td>0</td>\n",
       "      <td>-77.922077</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZKIN</th>\n",
       "      <td>5.488438e+07</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>3.659379e+07</td>\n",
       "      <td>1.829059e+07</td>\n",
       "      <td>1.652633e+06</td>\n",
       "      <td>7.020320e+06</td>\n",
       "      <td>8.672953e+06</td>\n",
       "      <td>9.617636e+06</td>\n",
       "      <td>1.239170e+06</td>\n",
       "      <td>8.416324e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.2489</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>-0.0968</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.834400</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZOM</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.031715e+07</td>\n",
       "      <td>4.521349e+06</td>\n",
       "      <td>1.664863e+07</td>\n",
       "      <td>-1.664863e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.664769e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1568</td>\n",
       "      <td>-0.2200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.7499</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>7</td>\n",
       "      <td>-73.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYME</th>\n",
       "      <td>5.301900e+07</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.301900e+07</td>\n",
       "      <td>5.668400e+07</td>\n",
       "      <td>2.945700e+07</td>\n",
       "      <td>8.614600e+07</td>\n",
       "      <td>-3.312700e+07</td>\n",
       "      <td>1.660000e+05</td>\n",
       "      <td>-3.438500e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>6</td>\n",
       "      <td>209.462222</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22077 rows Ã— 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
       "PG    7.440100e+10         -0.0713     3.903000e+10  3.537100e+10   \n",
       "VIPS  3.734148e+09          1.1737     2.805625e+09  9.285226e+08   \n",
       "KR    9.837500e+10          0.0182     7.813800e+10  2.023700e+10   \n",
       "RAD   2.552641e+10          0.0053     1.820268e+10  7.323734e+09   \n",
       "GIS   1.790960e+10          0.0076     1.153980e+10  6.369800e+09   \n",
       "...            ...             ...              ...           ...   \n",
       "YRIV  0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
       "YTEN  5.560000e+05         -0.4110     0.000000e+00  5.560000e+05   \n",
       "ZKIN  5.488438e+07          0.2210     3.659379e+07  1.829059e+07   \n",
       "ZOM   0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
       "ZYME  5.301900e+07          0.0243     0.000000e+00  5.301900e+07   \n",
       "\n",
       "      R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
       "PG    0.000000e+00  2.146100e+10        2.146100e+10      1.391000e+10   \n",
       "VIPS  1.083303e+08  3.441414e+08        7.939267e+08      1.345959e+08   \n",
       "KR    0.000000e+00  1.519600e+10        1.751200e+10      2.725000e+09   \n",
       "RAD   0.000000e+00  6.561162e+09        6.586482e+09      7.372520e+08   \n",
       "GIS   0.000000e+00  3.474300e+09        3.412400e+09      2.957400e+09   \n",
       "...            ...           ...                 ...               ...   \n",
       "YRIV  0.000000e+00  3.755251e+06        3.755251e+06     -3.755251e+06   \n",
       "YTEN  4.759000e+06  5.071000e+06        9.830000e+06     -9.274000e+06   \n",
       "ZKIN  1.652633e+06  7.020320e+06        8.672953e+06      9.617636e+06   \n",
       "ZOM   1.031715e+07  4.521349e+06        1.664863e+07     -1.664863e+07   \n",
       "ZYME  5.668400e+07  2.945700e+07        8.614600e+07     -3.312700e+07   \n",
       "\n",
       "      Interest Expense  Earnings before Tax  ...  Inventory Growth  \\\n",
       "PG        7.090000e+08         1.449400e+10  ...           -0.0217   \n",
       "VIPS      1.214869e+07         1.753823e+08  ...               NaN   \n",
       "KR        4.430000e+08         2.270000e+09  ...            0.0981   \n",
       "RAD       4.245910e+08         2.502180e+08  ...           -0.0510   \n",
       "GIS       3.024000e+08         2.707700e+09  ...            0.0090   \n",
       "...                ...                  ...  ...               ...   \n",
       "YRIV      1.105849e+07        -1.482451e+07  ...            0.0000   \n",
       "YTEN      0.000000e+00        -9.170000e+06  ...            0.0000   \n",
       "ZKIN      1.239170e+06         8.416324e+06  ...            0.7706   \n",
       "ZOM       0.000000e+00        -1.664769e+07  ...            0.0000   \n",
       "ZYME      1.660000e+05        -3.438500e+07  ...            0.0000   \n",
       "\n",
       "      Asset Growth  Book Value per Share Growth  Debt Growth  \\\n",
       "PG          0.0359                       0.0316       0.1228   \n",
       "VIPS           NaN                          NaN          NaN   \n",
       "KR          0.1886                       0.3268       0.2738   \n",
       "RAD        -0.0189                       0.1963      -0.0458   \n",
       "GIS         0.0215                       0.0274       0.1025   \n",
       "...            ...                          ...          ...   \n",
       "YRIV       -0.0508                      -0.1409      -0.0152   \n",
       "YTEN       -0.2323                      -0.8602       0.0000   \n",
       "ZKIN        0.2489                       0.4074      -0.0968   \n",
       "ZOM         0.1568                      -0.2200       0.0000   \n",
       "ZYME        0.8519                       0.1325       0.0000   \n",
       "\n",
       "      R&D Expense Growth  SG&A Expenses Growth  Sector   PRICE_VAR  Class  \\\n",
       "PG                0.0000               -0.1746       3   -9.323276      0   \n",
       "VIPS              1.6484                1.7313       3  -25.512193      0   \n",
       "KR                0.0000                0.0234       3   33.118297      1   \n",
       "RAD               0.0000               -0.0060       3    2.752291      1   \n",
       "GIS               0.0000               -0.0220       3   12.897715      1   \n",
       "...                  ...                   ...     ...         ...    ...   \n",
       "YRIV              0.0000               -0.2602       8  -90.962099      0   \n",
       "YTEN              0.0352               -0.0993       0  -77.922077      0   \n",
       "ZKIN              0.2415                0.8987       0  -17.834400      0   \n",
       "ZOM               2.7499                0.1457       7  -73.520000      0   \n",
       "ZYME              0.3577                0.5880       6  209.462222      1   \n",
       "\n",
       "      year  \n",
       "PG    2014  \n",
       "VIPS  2014  \n",
       "KR    2014  \n",
       "RAD   2014  \n",
       "GIS   2014  \n",
       "...    ...  \n",
       "YRIV  2018  \n",
       "YTEN  2018  \n",
       "ZKIN  2018  \n",
       "ZOM   2018  \n",
       "ZYME  2018  \n",
       "\n",
       "[22077 rows x 225 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining the datasets with an outer join to make a huge df\n",
    "\n",
    "df=pd.concat([df14,df15,df16,df17,df18])\n",
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17685, 225)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#creating train and test data in spirit of time series analysis\n",
    "\n",
    "X_train=pd.concat([df14,df15,df16,df17])\n",
    "X_test=df18\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many NAs are there and the percentage of missing values\n",
    "df.isnull().sum().sort_values(ascending=False)/len(df)\n",
    "\n",
    "def drop_na(data):\n",
    "    #dropping the columns with more than one third of the cells missing\n",
    "    df.dropna(axis=\"columns\", thresh=(1/3)*len(df))\n",
    "\n",
    "#pipeline\n",
    "drop=Pipeline(steps=[(\"drop_na\",drop_na(all_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jan Beeler\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataFrame'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9086953c6101>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mimputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mimpute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"imputer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-9086953c6101>\u001b[0m in \u001b[0;36mimputer\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimputer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIterativeImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf_filled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \"\"\"\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_indicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mX_indicator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_indicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_missing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_imputation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_missing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py\u001b[0m in \u001b[0;36m_initial_imputation\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         X = self._validate_data(X, dtype=FLOAT_DTYPES, order=\"F\",\n\u001b[0m\u001b[0;32m    499\u001b[0m                                 force_all_finite=force_all_finite)\n\u001b[0;32m    500\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#imputer\n",
    "\n",
    "#handling NAs with a multivariate feature imputation which essentially regresses column x_i with i=1,...N on columns X_{-i} and predicts the missing values\n",
    "#takes a lot of time; does not work yet I think!\n",
    "\n",
    "def imputer(data):\n",
    "    \n",
    "    imputer=IterativeImputer(max_iter=1,random_state=0)\n",
    "    imputer.fit(data)\n",
    "    df_filled=imputer.transform(data)\n",
    "\n",
    "    return df_filled\n",
    "\n",
    "imputer(df)\n",
    "\n",
    "impute=Pipeline(steps=[(\"imputer\",imputer(all_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers (saw that in the description)\n",
    "\n",
    "# Get stocks that increased more than 200%\n",
    "gain = 200\n",
    "top_gainers = df[df[\"PRICE_VAR\"] >= gain]\n",
    "top_gainers = top_gainers[\"PRICE_VAR\"].sort_values(ascending=False)\n",
    "print(f\"{len(top_gainers)} STOCKS with more than {gain}% gain.\")\n",
    "\n",
    "#we have 231 stocks with more than 200% gain\n",
    "\n",
    "#we do not want these stocks as we think that they are \"faked\" (or typos etc.)\n",
    "\n",
    "df = df.drop(top_gainers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#outliers (saw that in the description)\n",
    "\n",
    "#df14_outliers=df14.loc[:,[\"Sector\", \"2015 PRICE VAR [%]\"]]\n",
    "\n",
    "#sector_list=df14_outliers[\"Sector\"].unique()\n",
    "\n",
    "#plot the price variations per sector\n",
    "#for sector in sector_list:\n",
    "    \n",
    "    #temp=df14_outliers[df14_outliers[\"Sector\"] == sector]\n",
    "    \n",
    "    #plt.figure(figsize=(30,5))\n",
    "    #plt.plot(temp[\"2015 PRICE VAR [%]\"])\n",
    "    #plt.title(sector.upper(),fontsize=20)\n",
    "    #plt.show()\n",
    "\n",
    "#price_growth=500\n",
    "#gains=df14_outliers[df14_outliers[\"2015 PRICE VAR [%]\"]>=price_growth]\n",
    "#print(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buy: excess return >= 2.5\n",
    "# hold: 2.5 > excess return > -2.5\n",
    "# sell: -2.5 >= excess return\n",
    "\n",
    "df14.rename(columns={\"2015 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df15.rename(columns={\"2016 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df16.rename(columns={\"2017 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df17.rename(columns={\"2018 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df18.rename(columns={\"2019 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "\n",
    "all_data = [df14, df15, df16, df17, df18]\n",
    "\n",
    "for data in all_data:\n",
    "    data[\"buy\"] = np.where((data[\"PRICE_VAR\"].subtract(sp14_performance)) >= 2.5, [1], [0])\n",
    "    data[\"hold\"] = np.where((data[\"PRICE_VAR\"].subtract(sp14_performance) < 2.5) &\n",
    "                        (data[\"PRICE_VAR\"].subtract(sp14_performance) > -2.5), [1], [0])\n",
    "    data[\"sell\"] = np.where((data[\"PRICE_VAR\"].subtract(sp14_performance)) <= -2.5, [1], [0])\n",
    "    \n",
    "\n",
    "df14[[\"buy\", \"hold\", \"sell\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for just one column (problem with length)\n",
    "\n",
    "all_data = [df14, df15, df16, df17, df18]\n",
    "sp_performances\n",
    "\n",
    "for data, value in zip(all_data,sp_performances):\n",
    "        data[\"strategy\"] = np.where((data[\"PRICE_VAR\"].subtract(sp_performances)) >= 2.5, [\"buy\"], [\"\"])\n",
    "        data[\"strategy\"] = np.where((data[\"PRICE_VAR\"].subtract(sp_performances) < 2.5) &\n",
    "                            (data[\"PRICE_VAR\"].subtract(sp_performances) > -2.5), [\"hold\"], [\"\"])\n",
    "        data[\"strategy\"] = np.where((data[\"PRICE_VAR\"].subtract(sp_performances)) <= -2.5, [\"sell\"], [\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation function for the algos (from towards data science; might be useful later)\n",
    "\n",
    "def evaluation(y, y_hat, title = 'Confusion Matrix'):\n",
    "    cm = confusion_matrix(y, y_hat)\n",
    "    precision = precision_score(y, y_hat)\n",
    "    recall = recall_score(y, y_hat)\n",
    "    accuracy = accuracy_score(y,y_hat)\n",
    "    f1 = f1_score(y,y_hat)\n",
    "    print('Recall: ', recall)\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('Precision: ', precision)\n",
    "    print('F1: ', f1)\n",
    "    sns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})\n",
    "    plt.xlabel('predicted', fontsize=18)\n",
    "    plt.ylabel('actual', fontsize=18)\n",
    "    plt.title(title, fontsize=18)\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines:\n",
    "from sklearn.pipeline import Pipeline as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelining all of the above to prevent leakage from test data into training data which might be useful later (from tds)\n",
    "def cross_validate(classifier, cv):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocess', preprocess),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for train_ind, val_ind in cv.split(X_train, y_train):\n",
    "        X_t, y_t = X_train.iloc[train_ind], y_train[train_ind]\n",
    "        pipeline.fit(X_t, y_t)\n",
    "        y_hat_t = pipeline.predict(X_t)\n",
    "        train_acc.append(accuracy_score(y_t, y_hat_t))\n",
    "        X_val, y_val = X_train.iloc[val_ind], y_train[val_ind]\n",
    "        y_hat_val = pipeline.predict(X_val)\n",
    "        test_acc.append(accuracy_score(y_val, y_hat_val))\n",
    "    print(evaluation(y_val, y_hat_val))\n",
    "    print('Training Accuracy: {}'.format(np.mean(train_acc)))\n",
    "    print('\\n')\n",
    "    print('Validation Accuracy: {}'.format(np.mean(test_acc)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
